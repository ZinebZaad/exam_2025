{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problème n°2: PointNet"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certains jeux de données impliquent des nuages de points dans un espace 3D. Penser par exemple à un ensemble de mesures lidar : chaque tir permet de renseigner les coordonnées d'un des points de l'objet ciblé.\n",
        "Une tâche intéressante consiste à classer chacun des points du nuage en fonction de l'objet auquel il appartient. Cette tâche est considérée comme une variante de la segmentation sémantique d'images.\n",
        "\n",
        "Ce problème introduit à une méthode directe de segmentation d'un nuage par deep learning. Elle est basée sur une architecture particulière appelée PointNet. \\\n",
        "Dans la première partie, on présente un jeu de données (synthétisé à la volée) impliquant des nuages de points.\n",
        "Dans la seconde partie, on explore la structure et les propriétés de PointNet. Dans la troisième, on l'entraîne et dans la dernière partie, on charge les poids d'une version améliorée de PointNet (PointNet++) pour comparaison.\n",
        "\n",
        "La cellule suivante permet les imports nécessaires:"
      ],
      "metadata": {
        "id": "rPIFraX86pZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "! pip install einops\n",
        "! git clone https://github.com/ZinebZaad/exam_2025.git\n",
        "! cp exam_2025/utils/utils_probleme2.py .\n",
        "from utils_probleme2 import gen_pointcloud, plot_triplets"
      ],
      "metadata": {
        "id": "VMhc4--pzPdB",
        "outputId": "6c8cb3da-28d1-4862-b60c-1aa420d2988f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Cloning into 'exam_2025'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 83 (delta 5), reused 3 (delta 3), pack-reused 74 (from 2)\u001b[K\n",
            "Receiving objects: 100% (83/83), 2.35 MiB | 25.29 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie I : un exemple de PointCLoud data"
      ],
      "metadata": {
        "id": "OXcPslsLOKEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour construire le jeu de données, on simule un terrain couvert de deux types de bâtiments : des immeubles de forme rectangulaire aux toits plats et des igloos (dômes). Pour créer les nuages, on échantillonne les surfaces vues du ciel (les murs des bâtiments rectangulaires ne sont pas échantillonnées), en favorisant les zones d'altitude non nulles.\n",
        "Le but est de distinguer les igloos du reste (sol et toits des bâtiments). Il s'agit donc d'une segmentation binaire."
      ],
      "metadata": {
        "id": "GDqmLGFROPJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 6\n",
        "input_points, target_list, target_points  = gen_pointcloud(batch_size)\n",
        "\n",
        "\n",
        "for i in range(batch_size):\n",
        "  print(i)\n",
        "  # Représentation 3D des nuages de points et\n",
        "  # les paramètres elev et azim permettent de changer l'angle de vue\n",
        "  plot_triplets(input_points[i].transpose(0,1).cpu(),\n",
        "                elev=75, azim=0)\n",
        "\n",
        "  # Cibles : les points appartenant aux toitures d'igloos sont\n",
        "  # dans la classe 1, les autres, dans la classe 0.\n",
        "  plot_triplets(target_points[i].transpose(0,1).cpu(),\n",
        "                title='Cibles',\n",
        "                cbar_label='classe')\n",
        "\n",
        "  # Note: target_points contient non seulement les classes\n",
        "  # mais aussi les coordonnées x et y des points, pour\n",
        "  # faciliter leur visualisation"
      ],
      "metadata": {
        "id": "uBvv7mzq8SXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** A quoi correspondent les différentes dimensions de *input_points* ?"
      ],
      "metadata": {
        "id": "Ec1hdpYKWqtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER:\n",
        "\n",
        "The dimensions of $\\text{input_points}$ represent the structure of 3D point clouds. The first dimension ($\\text{batch_size}$) corresponds to the number of point clouds in the batch. The second dimension ($\\text{num_points}$) represents the number of points in each cloud, and the third dimension ($\\text{num_features}$) corresponds to the features of each point, typically the spatial coordinates $x$, $y$, and $z$. For example, a shape of $(6, 1024, 3)$ indicates 6 point clouds, each containing 1024 points described by 3 features (coordinates).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fhc1V-hhwVqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Les points d'un nuage sont-ils rangés dans un ordre particulier ?"
      ],
      "metadata": {
        "id": "O29XO_-BXW3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER:\n",
        "\n",
        "The points in a point cloud are not arranged in any specific order; they are typically distributed randomly across the visible surfaces of objects. In the case of the gen_pointcloud function, points are sampled randomly from surfaces such as building roofs or igloos to simulate realistic data, like LIDAR measurements. This lack of order means that the sequence of points in each cloud is neither structured nor meaningful for the segmentation task. Models like PointNet are designed to be permutation-invariant, ensuring that their processing and performance are not affected by the order of points within a cloud."
      ],
      "metadata": {
        "id": "-C-s0n2TwxKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** (question ouverte). Si vous deviez traiter le problème avec un FCN ou un ViT (Visual Transformer), que feriez-vous ?"
      ],
      "metadata": {
        "id": "9VdTYIGMZkYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER:\n",
        "\n",
        "Pour traiter le problème de segmentation d'un nuage de points 3D avec un Fully Convolutional Network (FCN) ou un Visual Transformer (ViT), il faudrait adapter les données et la méthode aux caractéristiques spécifiques de ces architectures. Avec un FCN, les nuages de points pourraient être projetés en 2D, par exemple en utilisant une vue de dessus (bird's-eye view) ou des projections multi-vues, ou convertis en une représentation volumétrique comme des voxels. Une fois les données structurées, un FCN peut segmenter les points en classifiant chaque pixel (2D) ou voxel (3D), avec un post-traitement pour attribuer les classes aux points originaux. En revanche, avec un ViT, les nuages de points pourraient être divisés en clusters ou \"patches\", chacun représenté par des descripteurs géométriques, pour former une séquence d'entrée. Le ViT utiliserait son mécanisme d'attention pour capturer les relations spatiales entre les patches et produire une segmentation précise. Le choix entre ces deux approches dépend des contraintes : un FCN est plus adapté pour des données structurées comme des voxels ou des projections, tandis qu’un ViT est mieux adapté aux données non structurées mais nécessite plus de ressources pour traiter de longues séquences ou capturer la géométrie complexe.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aHIkKKLOxvgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie II : le modèle PointNet"
      ],
      "metadata": {
        "id": "Oi-tMb6eVseg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on s'intéresse à la propriété principale d'un réseau PointNet : l'utilisation d'opérations invariantes par rapport à l'ordre dans lequel les points sont présentés au réseau."
      ],
      "metadata": {
        "id": "ymRoRLYE1_AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_probleme2 import PointNetSegHead\n",
        "pointnet = PointNetSegHead(num_points=800, num_global_feats=1024, m=2).cuda()\n",
        "\n",
        "input_points, target_list, _ = gen_pointcloud(batch_size)\n",
        "input_points = input_points.cuda()\n",
        "output, _, _ = pointnet(input_points)"
      ],
      "metadata": {
        "id": "S04tXJXHQWJ4",
        "outputId": "0cc04115-dc5a-41a0-ced8-f733d1f4c8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils_probleme2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2b2ad8afa2ef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils_probleme2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPointNetSegHead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpointnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointNetSegHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_global_feats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_pointcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils_probleme2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** La sortie du modèle PointNet correspond au premier tenseur du *tuple* fourni la fonction *forward* de *pointnet*. A quoi correspondent les différentes dimensions de *output* ? Quel est l'effet d'une permutation des points contenus dans *inputs_points* sur la sortie ? Répondre :\n",
        "\n",
        "- en vous référant à l'article [l'article](https://arxiv.org/abs/1612.00593) qui introduit ce réseau (citer dans le texte).\n",
        "- à partir de tests à effectuer dans la cellule de code suivante (utiliser torch.randperm pour générer des permutations sur les entrées)"
      ],
      "metadata": {
        "id": "JzuMy_0l2Kbr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99d6FryC7Bty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** L'architecture de *pointnet* est décrite dans la Figure 2 de l'article (voir ci-dessous) évoqué à la question précédente. En dehors des opérations notées \"input transform\" et \"feature transform\", dont la compréhension est plus délicate, quelles sont les différentes opérations conduisant à une segmentation ? Que signifie le terme \"shared\" et expliquer en quoi ces opérations sont invariantes par rapport à l'ordre de présentation des points."
      ],
      "metadata": {
        "id": "9a3Ag6gf7XWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://miro.medium.com/v2/resize:fit:1100/format:webp/1*lFnrIqmV_47iRvQcY3dB7Q.png >"
      ],
      "metadata": {
        "id": "Rhf7Jzr9yJwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie III"
      ],
      "metadata": {
        "id": "6ivNzt2E86eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on se propose d'entraîner un PointNet. Pour ce faire, on utilisera une fonction de coût spécifique (voir cellule ci-dessous).\n",
        "\n",
        "**Consignes :**\n",
        "\n",
        "1) Entraîner un PointNet sur quelques centaines d'époques.\n",
        "\n",
        "2) Afficher à chaque époque la justesse des prédictions\n",
        "\n",
        "3) Charger les poids d'un réseau entraîné sur 500 époques, stockés dans le fichier **pointnet_500_ep.pth** du répertoire https://huggingface.co/nanopiero/pointnet_igloos.\n",
        "\n",
        "Visualiser les sorties de ce modèle-là en complétant le la dernière cellule de code du calepin.\n"
      ],
      "metadata": {
        "id": "Hah5_qJ78-6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(pointnet.parameters(),\n",
        "                             lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "# manually set alpha weights\n",
        "alpha = np.array([0.2, 0.8])\n",
        "gamma = 1\n",
        "loss_fn = PointNetSegLoss(alpha=alpha, gamma=gamma, dice=True).cuda()\n",
        "\n",
        "# exemple d'utilisation de PointNetSegLoss:\n",
        "# La transposition permet de repasser la dimension relative\n",
        "# aux probabilités en dernier, comme avec torch.nn.CrossEntropyLoss\n",
        "proba_pred_list = outputs.transpose(1,2)\n",
        "loss_fn(proba_pred_list, target_list)"
      ],
      "metadata": {
        "id": "VwA_vclx0CWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "n_epochs = 200\n",
        "n_batch_per_epoch = 10\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs):\n",
        "  print('epoch : ', epoch)\n",
        "  for batch in range(1,n_batch_per_epoch):\n",
        "    ..."
      ],
      "metadata": {
        "id": "CNW_PJ_aAkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_points, target_list , target_points = gen_pointcloud(6)\n",
        "\n",
        "# Il faut construire les prédictions.\n",
        "proba_pred_list, _, _ = pointnet2.cuda()(input_points.to(device))\n",
        "pred_list = proba_pred_list.transpose(1,2).max(1)[1].cpu()\n",
        "\n",
        "# Accuracy:\n",
        "...\n",
        "# Tracé\n",
        "\n",
        "for i in range(6):\n",
        "  print(i)\n",
        "  plot_triplets(input_points[i].transpose(0,1), elev=75, azim=0)\n",
        "  plot_triplets(target_points[i].transpose(0,1),\n",
        "                title='Cibles',\n",
        "                cbar_label='classe')\n",
        "  plot_triplets(...,\n",
        "                title='Predictions',\n",
        "                cbar_label='classe')\n"
      ],
      "metadata": {
        "id": "OjFZ3ZNS-riv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}